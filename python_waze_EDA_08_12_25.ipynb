{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Waze Project**\n",
    "**Course 2 - Get Started with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCatj3xzrQZ"
   },
   "source": [
    "Welcome to the Waze Project!\n",
    "\n",
    "Your Waze data analytics team is still in the early stages of their user churn project. Previously, you were asked to complete a project proposal by your supervisor, May Santner. You have received notice that your project proposal has been approved and that your team has been given access to Waze's user data. To get clear insights, the user data must be inspected and prepared for the upcoming process of exploratory data analysis (EDA).\n",
    "\n",
    "A Python notebook has been prepared to guide you through this project. Answer the questions and create an executive summary for the Waze data team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# **Course 2 End-of-course project: Inspect and analyze data**\n",
    "\n",
    "In this activity, you will examine data provided and prepare it for analysis. This activity will help ensure the information is,\n",
    "\n",
    "1.   Ready to answer questions and yield insights\n",
    "\n",
    "2.   Ready for visualizations\n",
    "\n",
    "3.   Ready for future hypothesis testing and statistical methods\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this project is to investigate and understand the data provided.\n",
    "\n",
    "**The goal** is to use a dataframe contructed within Python, perform a cursory inspection of the provided dataset, and inform team members of your findings.\n",
    "<br/>\n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Understand the situation\n",
    "* How can you best prepare to understand and organize the provided information?\n",
    "\n",
    "**Part 2:** Understand the data\n",
    "\n",
    "* Create a pandas dataframe for data learning, future exploratory data analysis (EDA), and statistical activities\n",
    "\n",
    "* Compile summary information about the data to inform next steps\n",
    "\n",
    "**Part 3:** Understand the variables\n",
    "\n",
    "* Use insights from your examination of the summary data to guide deeper investigation into variables\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "Follow the instructions and answer the following questions to complete the activity. Then, you will complete an Executive Summary using the questions listed on the PACE Strategy Document.\n",
    "\n",
    "Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjFGokxv2pc5"
   },
   "source": [
    "# **Identify data types and compile summary information**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRUYfzCb4vop"
   },
   "source": [
    "\n",
    "\n",
    "# **PACE stages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4B47DQPcSQu"
   },
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework, PACE. The following notebook components are labeled with the respective PACE stages: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRHb2QQWj99m"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## **PACE: Plan**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWEfG5zJV5oG"
   },
   "source": [
    "### **Task 1. Understand the situation**\n",
    "\n",
    "*   How can you best prepare to understand and organize the provided driver data?\n",
    "\n",
    "\n",
    "*Begin by exploring your dataset and consider reviewing the Data Dictionary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irvqnKSe6Z80"
   },
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E9Y5aC0IAA-"
   },
   "source": [
    "\n",
    "\n",
    "## **PACE: Analyze**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4WK_AxP_S__"
   },
   "source": [
    "### **Task 2a. Imports and data loading**\n",
    "\n",
    "Start by importing the packages that you will need to load and explore the dataset. Make sure to use the following import statements:\n",
    "\n",
    "*   `import pandas as pd`\n",
    "\n",
    "*   `import numpy as np`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZSXM4q5zrQh"
   },
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "### YOUR CODE HERE ###\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-hT-EQA67v3"
   },
   "source": [
    "Then, load the dataset into a dataframe. Creating a dataframe will help you conduct data manipulation, exploratory data analysis (EDA), and statistical activities.\n",
    "\n",
    "**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('waze_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYx1emvno7U_"
   },
   "source": [
    "### **Task 2b. Summary information**\n",
    "\n",
    "View and inspect summary information about the dataframe by **coding the following:**\n",
    "\n",
    "1.   df.head(10)\n",
    "2.   df.info()\n",
    "\n",
    "*Consider the following questions:*\n",
    "\n",
    "1. When reviewing the `df.head()` output, are there any variables that have missing values?\n",
    "\n",
    "2. When reviewing the `df.info()` output, what are the data types? How many rows and columns do you have?\n",
    "\n",
    "3. Does the dataset have any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7Nck2hh4R6J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       14999 non-null  int64  \n",
      " 1   label                    14299 non-null  object \n",
      " 2   sessions                 14999 non-null  int64  \n",
      " 3   drives                   14999 non-null  int64  \n",
      " 4   total_sessions           14999 non-null  float64\n",
      " 5   n_days_after_onboarding  14999 non-null  int64  \n",
      " 6   total_navigations_fav1   14999 non-null  int64  \n",
      " 7   total_navigations_fav2   14999 non-null  int64  \n",
      " 8   driven_km_drives         14999 non-null  float64\n",
      " 9   duration_minutes_drives  14999 non-null  float64\n",
      " 10  activity_days            14999 non-null  int64  \n",
      " 11  driving_days             14999 non-null  int64  \n",
      " 12  device                   14999 non-null  object \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "df.head(10)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NctoTSAvGGD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                           0\n",
      "label                      700\n",
      "sessions                     0\n",
      "drives                       0\n",
      "total_sessions               0\n",
      "n_days_after_onboarding      0\n",
      "total_navigations_fav1       0\n",
      "total_navigations_fav2       0\n",
      "driven_km_drives             0\n",
      "duration_minutes_drives      0\n",
      "activity_days                0\n",
      "driving_days                 0\n",
      "device                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "## label has 700 missing values. it shows 14299.\n",
    "\n",
    "## Summary:\n",
    "## 13 columns\n",
    "## 14999 rows\n",
    "## 700 missing values on label column\n",
    "\n",
    "## Data Types:\n",
    "## Mixed integers, floats, and objects\n",
    "## 8 columns are int64\n",
    "## 3 columns are float64\n",
    "## 2 columns are object (including the label and device columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JscqNfr6ZVsE"
   },
   "source": [
    "==> ENTER YOUR RESPONSES TO QUESTIONS 1-3 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMNnIoc51_1N"
   },
   "source": [
    "### **Task 2c. Null values and summary statistics**\n",
    "\n",
    "Compare the summary statistics of the 700 rows that are missing labels with summary statistics of the rows that are not missing any values.\n",
    "\n",
    "**Question:** Is there a discernible difference between the two populations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAQeHW-d2S1-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing label rows:\n",
      "                  ID    sessions      drives  total_sessions  \\\n",
      "count    700.000000  700.000000  700.000000      700.000000   \n",
      "mean    7405.584286   80.837143   67.798571      198.483348   \n",
      "std     4306.900234   79.987440   65.271926      140.561715   \n",
      "min       77.000000    0.000000    0.000000        5.582648   \n",
      "25%     3744.500000   23.000000   20.000000       94.056340   \n",
      "50%     7443.000000   56.000000   47.500000      177.255925   \n",
      "75%    11007.000000  112.250000   94.000000      266.058022   \n",
      "max    14993.000000  556.000000  445.000000     1076.879741   \n",
      "\n",
      "       n_days_after_onboarding  total_navigations_fav1  \\\n",
      "count               700.000000              700.000000   \n",
      "mean               1709.295714              118.717143   \n",
      "std                1005.306562              156.308140   \n",
      "min                  16.000000                0.000000   \n",
      "25%                 869.000000                4.000000   \n",
      "50%                1650.500000               62.500000   \n",
      "75%                2508.750000              169.250000   \n",
      "max                3498.000000             1096.000000   \n",
      "\n",
      "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
      "count              700.000000        700.000000               700.000000   \n",
      "mean                30.371429       3935.967029              1795.123358   \n",
      "std                 46.306984       2443.107121              1419.242246   \n",
      "min                  0.000000        290.119811                66.588493   \n",
      "25%                  0.000000       2119.344818               779.009271   \n",
      "50%                 10.000000       3421.156721              1414.966279   \n",
      "75%                 43.000000       5166.097373              2443.955404   \n",
      "max                352.000000      15135.391280              9746.253023   \n",
      "\n",
      "       activity_days  driving_days  \n",
      "count     700.000000    700.000000  \n",
      "mean       15.382857     12.125714  \n",
      "std         8.772714      7.626373  \n",
      "min         0.000000      0.000000  \n",
      "25%         8.000000      6.000000  \n",
      "50%        15.000000     12.000000  \n",
      "75%        23.000000     18.000000  \n",
      "max        31.000000     30.000000  \n",
      "\n",
      " Non-missing label rows:\n",
      "                  ID      sessions        drives  total_sessions  \\\n",
      "count  14299.000000  14299.000000  14299.000000    14299.000000   \n",
      "mean    7503.573117     80.623820     67.255822      189.547409   \n",
      "std     4331.207621     80.736502     65.947295      136.189764   \n",
      "min        0.000000      0.000000      0.000000        0.220211   \n",
      "25%     3749.500000     23.000000     20.000000       90.457733   \n",
      "50%     7504.000000     56.000000     48.000000      158.718571   \n",
      "75%    11257.500000    111.000000     93.000000      253.540450   \n",
      "max    14998.000000    743.000000    596.000000     1216.154633   \n",
      "\n",
      "       n_days_after_onboarding  total_navigations_fav1  \\\n",
      "count             14299.000000            14299.000000   \n",
      "mean               1751.822505              121.747395   \n",
      "std                1008.663834              147.713428   \n",
      "min                   4.000000                0.000000   \n",
      "25%                 878.500000               10.000000   \n",
      "50%                1749.000000               71.000000   \n",
      "75%                2627.500000              178.000000   \n",
      "max                3500.000000             1236.000000   \n",
      "\n",
      "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
      "count            14299.000000      14299.000000             14299.000000   \n",
      "mean                29.638296       4044.401535              1864.199794   \n",
      "std                 45.350890       2504.977970              1448.005047   \n",
      "min                  0.000000         60.441250                18.282082   \n",
      "25%                  0.000000       2217.319909               840.181344   \n",
      "50%                  9.000000       3496.545617              1479.394387   \n",
      "75%                 43.000000       5299.972162              2466.928876   \n",
      "max                415.000000      21183.401890             15851.727160   \n",
      "\n",
      "       activity_days  driving_days  \n",
      "count   14299.000000  14299.000000  \n",
      "mean       15.544653     12.182530  \n",
      "std         9.016088      7.833835  \n",
      "min         0.000000      0.000000  \n",
      "25%         8.000000      5.000000  \n",
      "50%        16.000000     12.000000  \n",
      "75%        23.000000     19.000000  \n",
      "max        31.000000     30.000000  \n"
     ]
    }
   ],
   "source": [
    "# Isolate rows with null values\n",
    "### YOUR CODE HERE ###\n",
    "missing_label = df [df['label'].isnull() ] not_missing_label = df [df['label'].notnull() ] # Display summary stats of rows with null values\n",
    "### YOUR CODE HERE ###\n",
    "print(\n",
    "    \"Missing label rows:\\n\",\n",
    "    missing_label.describe()\n",
    ") print(\n",
    "    \"\\n Non-missing label rows:\\n\",\n",
    "    not_missing_label.describe()\n",
    ") ## print(missing_label.describe)\n",
    "## print(not_missing_label.describe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W77hp8q3w-zi"
   },
   "outputs": [],
   "source": [
    "# Isolate rows without null values\n",
    "### YOUR CODE HERE ###\n",
    "missing_label = df[df['label'].isnull()]\n",
    "# Display summary stats of rows without null values\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "not_missing_label = df[df['label'].notnull()]\n",
    "\n",
    "#There is no discernable difference in means between the 700 rows with no label\n",
    "# and the 14249 with label. Mean 80.3 vs. 80.6, not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2CupDgSlpm4"
   },
   "source": [
    "### **Task 2d. Null values - device counts**\n",
    "\n",
    "Next, check the two populations with respect to the `device` variable.\n",
    "\n",
    "**Question:** How many iPhone users had null values and how many Android users had null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbCnokO8lsq3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone     447\n",
      "Android    253\n",
      "Name: device, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get count of null values by device\n",
    "### YOUR CODE HERE ###\n",
    "#null_device_counts = missing_label['device'].value_counts('device')\n",
    "\n",
    "#null_device_counts = missing_label['device'].value_counts('device')\n",
    "\n",
    "# Count how many rows have null label for each device type\n",
    "\n",
    "#null_device_counts = missing_label['device'].value_counts()\n",
    "\n",
    "#null_device_counts = missing_label['device'].value_counts('device')\n",
    "\n",
    "# Count how many rows have null label for each device type\n",
    "null_device_counts = missing_label['device'].value_counts()\n",
    "print(null_device_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mean 80.3 vs. 80.6, not significant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajlCljYHmCTa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count  percentage\n",
      "iPhone     447        63.9\n",
      "Android    253        36.1\n"
     ]
    }
   ],
   "source": [
    "# Calculate % of iPhone nulls and Android nulls\n",
    "### YOUR CODE HERE ###\n",
    "counts = missing_label['device'].value_counts()\n",
    "percentages =  missing_label['device'].value_counts(normalize=True).mul(100).round(1)\n",
    "result = pd.concat([counts, percentages], axis=1, keys=['count', 'percentage'])\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dA_ps_fA3xn9"
   },
   "source": [
    "How does this compare to the device ratio in the full dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dm-qKyQNmCsQ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count  percentage\n",
      "iPhone     447        63.9\n",
      "Android    253        36.1\n",
      "         count  percentage\n",
      "iPhone    9672        64.5\n",
      "Android   5327        35.5\n",
      "\n",
      "Device ratios for rows with missing labels:\n",
      "\n",
      "         count  percentage\n",
      "iPhone     447        63.9\n",
      "Android    253        36.1\n"
     ]
    }
   ],
   "source": [
    "# Calculate % of iPhone users and Android users in full dataset\n",
    "### YOUR CODE HERE ###\n",
    "counts = df['device'].value_counts()\n",
    "ratio = df / result\n",
    "percentages =  df['device'].value_counts(normalize=True).mul(100).round(1)\n",
    "full_dataset_device_ratio = pd.concat([counts, percentages], axis=1, keys=['count', 'percentage'])\n",
    "print(result)\n",
    "\n",
    "# Get raw counts of devices in full dataset\n",
    "counts = df['device'].value_counts()\n",
    "\n",
    "# Get percentages of devices in full dataset\n",
    "percentages = df['device'].value_counts(normalize=True).mul(100).round(1)\n",
    "\n",
    "# Combine counts and percentages side-by-side into a DataFrame\n",
    "full_dataset_device_ratio = pd.concat([counts, percentages], axis=1, keys=['count', 'percentage'])\n",
    "\n",
    "# Print the full dataset device ratio table\n",
    "print(full_dataset_device_ratio)\n",
    "\n",
    "print(\"\\nDevice ratios for rows with missing labels:\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEIeGZdgmRh9"
   },
   "source": [
    "The percentage of missing values by each device is consistent with their representation in the data overall.\n",
    "\n",
    "There is nothing to suggest a non-random cause of the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIzg4fXtmSTe"
   },
   "source": [
    "Examine the counts and percentages of users who churned vs. those who were retained. How many of each group are represented in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQ1mu8g9maYX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retained    11763\n",
      "churned      2536\n",
      "Name: label, dtype: int64\n",
      "retained    82.3\n",
      "churned     17.7\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate counts of churned vs. retained\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Filter out missing labels\n",
    "labeled_df = df[df['label'].notnull()]\n",
    "\n",
    "# Counts\n",
    "churn_counts = labeled_df['label'].value_counts()\n",
    "print(churn_counts)\n",
    "\n",
    "# Percentages\n",
    "churn_percentages = labeled_df['label'].value_counts(normalize=True).mul(100).round(1)\n",
    "print(churn_percentages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYTZIIOKmfIz"
   },
   "source": [
    "This dataset contains 82% retained users and 18% churned users.\n",
    "\n",
    "Next, compare the medians of each variable for churned and retained users. The reason for calculating the median and not the mean is that you don't want outliers to unduly affect the portrayal of a typical user. Notice, for example, that the maximum value in the `driven_km_drives` column is 21,183 km. That's more than half the circumference of the earth!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzngebHRmmFA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
      "label                                                                         \n",
      "churned   7477.5      59.0    50.0      164.339042                   1321.0   \n",
      "retained  7509.0      56.0    47.0      157.586756                   1843.0   \n",
      "\n",
      "          total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
      "label                                                                        \n",
      "churned                     84.5                    11.0       3652.655666   \n",
      "retained                    68.0                     9.0       3464.684614   \n",
      "\n",
      "          duration_minutes_drives  activity_days  driving_days  \n",
      "label                                                           \n",
      "churned               1607.183785            8.0           6.0  \n",
      "retained              1458.046141           17.0          14.0  \n"
     ]
    }
   ],
   "source": [
    "# Calculate median values of all columns for churned and retained users\n",
    "### YOUR CODE HERE ###\n",
    "churn_median = labeled_df.groupby('label').median(numeric_only=True)\n",
    "print(churn_median)\n",
    "#churn_median = labeled_df.groupby('label').median(numeric_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvnPFKS3mm71"
   },
   "source": [
    "This offers an interesting snapshot of the two groups, churned vs. retained:\n",
    "\n",
    "Users who churned averaged ~3 more drives in the last month than retained users, but retained users used the app on over twice as many days as churned users in the same time period.\n",
    "\n",
    "The median churned user drove ~200 more kilometers and 2.5 more hours during the last month than the median retained user.\n",
    "\n",
    "It seems that churned users had more drives in fewer days, and their trips were farther and longer in duration. Perhaps this is suggestive of a user profile. Continue exploring!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUAkU-JInALK"
   },
   "source": [
    "Calculate the median kilometers per drive in the last month for both retained and churned users.\n",
    "\n",
    "Begin by dividing the `driven_km_drives` column by the `drives` column. Then, group the results by churned/retained and calculate the median km/drive of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVcP2PPhnBMZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "churned     74.109416\n",
      "retained    75.014702\n",
      "Name: km_per_drive, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add km_per_drive column to df\n",
    "df['km_per_drive'] = df['driven_km_drives'] / df['drives']\n",
    "\n",
    "# Recreate labeled_df so it includes that new column\n",
    "labeled_df = df[df['label'].notnull()]\n",
    "\n",
    "# Group by label and calculate median km_per_drive\n",
    "km_per_drive_median = labeled_df.groupby('label')['km_per_drive'].median()\n",
    "\n",
    "# Display result\n",
    "print(km_per_drive_median)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6VicaRVnFzq"
   },
   "source": [
    "The median retained user drove about one more kilometer per drive than the median churned user. How many kilometers per driving day was this?\n",
    "\n",
    "To calculate this statistic, repeat the steps above using `driving_days` instead of `drives`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6lD33kfnGQb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "churned     697.541999\n",
      "retained    289.549333\n",
      "Name: km_per_drive, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add km_per_drive column to df\n",
    "df['km_per_drive'] = df['driven_km_drives'] / df['driving_days']\n",
    "\n",
    "# Recreate labeled_df so it includes that new column\n",
    "labeled_df = df[df['label'].notnull()]\n",
    "\n",
    "# Group by label and calculate median km_per_drive\n",
    "km_per_day_median = labeled_df.groupby('label')['km_per_drive'].median()\n",
    "\n",
    "# Display result\n",
    "print(km_per_day_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIfSmukAnVSs"
   },
   "source": [
    "Now, calculate the median number of drives per driving day for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAHqOO8endWX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "churned     697.541999\n",
      "retained    289.549333\n",
      "Name: km_per_driving_day, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add a column to df called `drives_per_driving_day`\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Create km_per_driving_day = kilometers driven per day with at least one drive\n",
    "df['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\n",
    "\n",
    "# Recreate labeled_df so it has the new column and only labeled users\n",
    "labeled_df = df[df['label'].notnull()]\n",
    "\n",
    "# Group by 'label' and calculate the median km_per_driving_day\n",
    "km_per_driving_day_median = labeled_df.groupby('label')['km_per_driving_day'].median()\n",
    "\n",
    "# Display results\n",
    "print(km_per_driving_day_median)\n",
    "\n",
    "\n",
    "# Group by `label`, calculate the median, and isolate for drives per driving day\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVRAwsb1nv2L"
   },
   "source": [
    "The median user who churned drove 698 kilometers each day they drove last month, which is almost ~240% the per-drive-day distance of retained users. The median churned user had a similarly disproporionate number of drives per drive day compared to retained users.\n",
    "\n",
    "It is clear from these figures that, regardless of whether a user churned or not, the users represented in this data are serious drivers! It would probably be safe to assume that this data does not represent typical drivers at large. Perhaps the data&mdash;and in particular the sample of churned users&mdash;contains a high proportion of long-haul truckers.\n",
    "\n",
    "In consideration of how much these users drive, it would be worthwhile to recommend to Waze that they gather more data on these super-drivers. It's possible that the reason for their driving so much is also the reason why the Waze app does not meet their specific set of needs, which may differ from the needs of a more typical driver, such as a commuter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xc7Q6elLoD1R"
   },
   "source": [
    "Finally, examine whether there is an imbalance in how many users churned by device type.\n",
    "\n",
    "Begin by getting the overall counts of each device type for each group, churned and retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGkODIILoEp-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label     device \n",
      "churned   Android     891\n",
      "          iPhone     1645\n",
      "retained  Android    4183\n",
      "          iPhone     7580\n",
      "dtype: int64\n",
      "Counts by label and device:\n",
      "label     device \n",
      "churned   Android     891\n",
      "          iPhone     1645\n",
      "retained  Android    4183\n",
      "          iPhone     7580\n",
      "dtype: int64\n",
      "\n",
      "Counts table:\n",
      "device    Android  iPhone\n",
      "label                    \n",
      "churned       891    1645\n",
      "retained     4183    7580\n",
      "\n",
      "Percentages within each label:\n",
      "device    Android  iPhone\n",
      "label                    \n",
      "churned     35.13   64.87\n",
      "retained    35.56   64.44\n"
     ]
    }
   ],
   "source": [
    "# For each label, calculate the number of Android users and iPhone users\n",
    "### YOUR CODE HERE #### For each label, calculate the number of Android users and iPhone users,\n",
    "# using your real 'device' column (per your instruction)\n",
    "os_counts = labeled_df.groupby(['label', 'device']).size()\n",
    "\n",
    "print(os_counts)\n",
    "\n",
    "# Count Android and iPhone users for each label\n",
    "device_counts = labeled_df.groupby(['label', 'device']).size()\n",
    "\n",
    "# Display raw counts\n",
    "print(\"Counts by label and device:\")\n",
    "print(device_counts)\n",
    "\n",
    "# Convert to table form (labels as rows, device types as columns)\n",
    "device_table = device_counts.unstack(fill_value=0)\n",
    "print(\"\\nCounts table:\")\n",
    "print(device_table)\n",
    "\n",
    "# Calculate percentages within each label\n",
    "device_percent = device_table.divide(device_table.sum(axis=1), axis=0) * 100\n",
    "print(\"\\nPercentages within each label:\")\n",
    "print(device_percent.round(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTVM6qFkoJs4"
   },
   "source": [
    "Now, within each group, churned and retained, calculate what percent was Android and what percent was iPhone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rx0ElsS6oO7y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label     device \n",
      "churned   Android    35.134069\n",
      "          iPhone     64.865931\n",
      "retained  Android    35.560656\n",
      "          iPhone     64.439344\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# For each label, calculate the percentage of Android users and iPhone users\n",
    "### YOUR CODE HERE ###\n",
    "device_counts = labeled_df.groupby(['label', 'device']).size()\n",
    "label_totals = labeled_df.groupby('label').size()\n",
    "device_percent = (device_counts / label_totals) * 100\n",
    "print(device_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQVIMPzroavO"
   },
   "source": [
    "The ratio of iPhone users and Android users is consistent between the churned group and the retained group, and those ratios are both consistent with the ratio found in the overall dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF_82VLgzrQm",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## **PACE: Construct**\n",
    "\n",
    "**Note**: The Construct stage does not apply to this workflow. The PACE framework can be adapted to fit the specific requirements of any project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMHV86A6zrQo"
   },
   "source": [
    "\n",
    "\n",
    "## **PACE: Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document and those below to craft your response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3HxcMZgz6iW"
   },
   "source": [
    "### **Task 3. Conclusion**\n",
    "\n",
    "Recall that your supervisor, May Santer, asked you to share your findings with the data team in an executive summary. Consider the following questions as you prepare to write your summary. Think about key points you may want to share with the team, and what information is most relevant to the user churn project.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Did the data contain any missing values? How many, and which variables were affected? Was there a pattern to the missing data?\n",
    "\n",
    "2. What is a benefit of using the median value of a sample instead of the mean?\n",
    "\n",
    "3. Did your investigation give rise to further questions that you would like to explore or ask the Waze team about?\n",
    "\n",
    "4. What percentage of the users in the dataset were Android users and what percentage were iPhone users?\n",
    "\n",
    "5. What were some distinguishing characteristics of users who churned vs. users who were retained?\n",
    "\n",
    "6. Was there an appreciable difference in churn rate between iPhone users vs. Android users?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMHlK7k5_2PV"
   },
   "source": [
    "The data contained 700 missing label values. There was no consistent pattern to the missing data that surfaced on EDA. \n",
    "The benefit of the median is to control possible skewing by outliers that may not represent what we need to know from the data, particularly in the case of the stakeholder.\n",
    "Further questions are to track further stats on device to look for patterns that could relate to retention on either platform. (more soon...)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "11e8ZirEhEEhZj7pNZmB8r_dPDEwRnfPR",
     "timestamp": 1671051831339
    },
    {
     "file_id": "1SoZM3Yq8C8BdYu-st3_BAlhze2_Z6Ilb",
     "timestamp": 1668798742100
    },
    {
     "file_id": "1U6q6WFOo7_Ka_C9cdq49KwAsI_lFX86-",
     "timestamp": 1668698832849
    },
    {
     "file_id": "1h6rKqbyzegmvnh5T6X1MhTFOXE6VUciq",
     "timestamp": 1666209449412
    },
    {
     "file_id": "1Vz66UR_ImIhJ4HEkCzdY_9E9QLKiboV1",
     "timestamp": 1663780048645
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
